{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "c5c20782",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import yaml\n",
        "import sys\n",
        "import re\n",
        "\n",
        "# Add the FLARE directory to path\n",
        "sys.path.insert(0, '/home/vedantpu/.julia/dev/FLARE-dev.py/')\n",
        "\n",
        "import pdebench\n",
        "from pdebench.dataset.utils import load_dataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Base directories\n",
        "PROJDIR = '/home/vedantpu/.julia/dev/FLARE-dev.py'\n",
        "DATADIR_BASE = '/mnt/hdd1/vedantpu/data/' if os.path.exists('/mnt/hdd1/vedantpu/data/') else os.path.join(PROJDIR, 'data')\n",
        "CHECKPOINT_BASE = '/home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts'\n",
        "OUTPUT_BASE = '/home/vedantpu/.julia/dev/FLARE-dev.py/figs/vis_out'\n",
        "\n",
        "# Datasets to visualize\n",
        "# datasets_to_visualize = ['elasticity', 'darcy', 'airfoil_steady', 'pipe']\n",
        "datasets_to_visualize = ['elasticity', 'darcy', 'pipe']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "7ee8de3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "__all__ = [\n",
        "    \"FLAREModel\",\n",
        "]\n",
        "\n",
        "#======================================================================#\n",
        "# Activation Functions\n",
        "#======================================================================#\n",
        "ACTIVATIONS = {\n",
        "    'gelu': nn.GELU(approximate='tanh'),\n",
        "    'silu': nn.SiLU(),\n",
        "}\n",
        "\n",
        "#======================================================================#\n",
        "# Residual MLP Block\n",
        "#======================================================================#\n",
        "\n",
        "class ResidualMLP(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_dim: int, hidden_dim: int, out_dim: int, num_layers: int = 2,\n",
        "            act: str = None, input_residual: bool = False, output_residual: bool = False,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        assert self.num_layers >= -1, f\"num_layers must be at least -1. Got {self.num_layers}.\"\n",
        "\n",
        "        # nn.Linear if num_layers == -1\n",
        "        if self.num_layers == -1:\n",
        "            self.fc = nn.Linear(in_dim, out_dim)\n",
        "            self.residual = input_residual and output_residual and (in_dim == out_dim)\n",
        "            return\n",
        "\n",
        "        self.act = ACTIVATIONS[act] if act else ACTIVATIONS['gelu']\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fcs = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers)])\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "        self.input_residual  = input_residual  and (in_dim  == hidden_dim)\n",
        "        self.output_residual = output_residual and (hidden_dim == out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.num_layers == -1:\n",
        "            x = x + self.fc(x) if self.residual else self.fc(x)\n",
        "            return x\n",
        "\n",
        "        x = x + self.act(self.fc1(x)) if self.input_residual else self.act(self.fc1(x))\n",
        "        for fc in self.fcs:\n",
        "            x = x + self.act(fc(x))\n",
        "        x = x + self.fc2(x) if self.output_residual else self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "#======================================================================#\n",
        "# FLARE\n",
        "#======================================================================#\n",
        "class FLARE(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channel_dim: int,\n",
        "        num_heads: int = 8,\n",
        "        num_latents: int = 32,\n",
        "        attn_scale: float = 1.0,\n",
        "        act: str = None,\n",
        "        num_layers_kv_proj: int = 3,\n",
        "        kv_proj_mlp_ratio: float = 1.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channel_dim = channel_dim\n",
        "        self.num_latents = num_latents\n",
        "        self.num_heads = channel_dim // 8 if num_heads is None else num_heads\n",
        "        self.head_dim = self.channel_dim // self.num_heads\n",
        "\n",
        "        assert self.channel_dim % self.num_heads == 0, f\"channel_dim must be divisible by num_heads. Got {self.channel_dim} and {self.num_heads}.\"\n",
        "        assert attn_scale > 0.0, f\"attn_scale must be greater than 0. Got {attn_scale}.\"\n",
        "\n",
        "        self.attn_scale = attn_scale\n",
        "\n",
        "        self.latent_q = nn.Parameter(torch.empty(self.channel_dim, self.num_latents))\n",
        "        nn.init.normal_(self.latent_q, mean=0.0, std=0.1)\n",
        "\n",
        "        self.k_proj, self.v_proj = [\n",
        "            ResidualMLP(\n",
        "                in_dim=self.channel_dim,\n",
        "                hidden_dim=int(self.channel_dim * kv_proj_mlp_ratio),\n",
        "                out_dim=self.channel_dim,\n",
        "                num_layers=num_layers_kv_proj,\n",
        "                act=act,\n",
        "                input_residual=True,\n",
        "                output_residual=True,\n",
        "            ) for _ in range(2)\n",
        "        ]\n",
        "\n",
        "        self.out_proj = nn.Linear(self.channel_dim, self.channel_dim)\n",
        "\n",
        "    def forward(self, x, return_scores: bool = False):\n",
        "\n",
        "        # x: [B N C]\n",
        "\n",
        "        q = self.latent_q.view(self.num_heads, self.num_latents, self.head_dim) # [H M D]\n",
        "        k = rearrange(self.k_proj(x), 'b n (h d) -> b h n d', h=self.num_heads) # [B H N D]\n",
        "        v = rearrange(self.v_proj(x), 'b n (h d) -> b h n d', h=self.num_heads)\n",
        "\n",
        "        #--------------------------------------------#\n",
        "        if not return_scores:\n",
        "            q = q.unsqueeze(0).expand(x.size(0), -1, -1, -1) # required for fused attention\n",
        "            z = F.scaled_dot_product_attention(q, k, v, scale=self.attn_scale)\n",
        "            y = F.scaled_dot_product_attention(k, q, z, scale=self.attn_scale)\n",
        "            scores = None\n",
        "        else:\n",
        "            # (1) Compute projection weights\n",
        "            scores = q @ k.transpose(-2, -1) # [B H M N]\n",
        "            W_encode = F.softmax(scores, dim=-1)\n",
        "            W_decode = F.softmax(scores.transpose(-2, -1), dim=-1)\n",
        "\n",
        "            # (2) Project to latent sequence\n",
        "            z = W_encode @ v # [B H M D]\n",
        "\n",
        "            # (3) Project back to input space\n",
        "            y = W_decode @ z # [B H N D]\n",
        "        #--------------------------------------------#\n",
        "\n",
        "        y = rearrange(y, 'b h n d -> b n (h d)')\n",
        "        y = self.out_proj(y)\n",
        "\n",
        "        return y, scores\n",
        "\n",
        "#======================================================================#\n",
        "# FLARE Block\n",
        "#======================================================================#\n",
        "class FLAREBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channel_dim: int,\n",
        "        num_heads: int = None,\n",
        "        num_latents: int = None,\n",
        "        attn_scale: float = 1.0,\n",
        "        act: str = None,\n",
        "        rmsnorm: bool = False,\n",
        "        num_layers_kv_proj: int = 3,\n",
        "        num_layers_ffn: int = 3,\n",
        "        kv_proj_mlp_ratio: float = 1.0,\n",
        "        ffn_mlp_ratio: float = 1.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.RMSNorm(channel_dim) if rmsnorm else nn.LayerNorm(channel_dim)\n",
        "        self.ln2 = nn.RMSNorm(channel_dim) if rmsnorm else nn.LayerNorm(channel_dim)\n",
        "        self.att = FLARE(\n",
        "            channel_dim=channel_dim,\n",
        "            num_heads=num_heads,\n",
        "            num_latents=num_latents,\n",
        "            attn_scale=attn_scale,\n",
        "            act=act,\n",
        "            num_layers_kv_proj=num_layers_kv_proj,\n",
        "            kv_proj_mlp_ratio=kv_proj_mlp_ratio,\n",
        "        )\n",
        "        self.mlp = ResidualMLP(\n",
        "            in_dim=channel_dim,\n",
        "            hidden_dim=int(channel_dim * ffn_mlp_ratio),\n",
        "            out_dim=channel_dim,\n",
        "            num_layers=num_layers_ffn,\n",
        "            act=act,\n",
        "            input_residual=True,\n",
        "            output_residual=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_scores: bool = False):\n",
        "        # x: [B, N, C]\n",
        "\n",
        "        # x = x + att(ln1(x))\n",
        "        # x = x + mlp(ln2(x))\n",
        "        # return x\n",
        "\n",
        "        _x, scores = self.att(self.ln1(x), return_scores=return_scores)\n",
        "        x = x + _x\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "\n",
        "        return x, scores\n",
        "\n",
        "#======================================================================#\n",
        "# MODEL\n",
        "#======================================================================#\n",
        "class FLAREModel(nn.Module):\n",
        "    def __init__(self,\n",
        "        in_dim: int,\n",
        "        out_dim: int,\n",
        "        channel_dim: int = 64,\n",
        "        num_blocks: int = 8,\n",
        "        num_heads: int = None,\n",
        "        act: str = None,\n",
        "        rmsnorm: bool = False,\n",
        "        out_proj_norm: bool = True,\n",
        "        num_layers_in_out_proj: int = 2,\n",
        "        #\n",
        "        attn_scale: float = 1.0,\n",
        "        num_latents: int = None,\n",
        "        num_layers_kv_proj: int = 3,\n",
        "        kv_proj_mlp_ratio: float = 1.0,\n",
        "        num_layers_ffn: int = 3,\n",
        "        ffn_mlp_ratio: float = 1.0,\n",
        "        #\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_proj = ResidualMLP(\n",
        "            in_dim=in_dim,\n",
        "            hidden_dim=channel_dim,\n",
        "            out_dim=channel_dim,\n",
        "            num_layers=num_layers_in_out_proj,\n",
        "            act=act,\n",
        "            input_residual=False,\n",
        "            output_residual=True,\n",
        "        )\n",
        "        \n",
        "        Norm = nn.RMSNorm if rmsnorm else nn.LayerNorm\n",
        "\n",
        "        self.out_proj = nn.ModuleDict()\n",
        "        if out_proj_norm:\n",
        "            self.out_proj['ln'] = Norm(channel_dim)\n",
        "        else:\n",
        "            self.out_proj['ln'] = nn.Identity()\n",
        "        self.out_proj['mlp'] = ResidualMLP(\n",
        "            in_dim=channel_dim,\n",
        "            hidden_dim=channel_dim,\n",
        "            out_dim=out_dim,\n",
        "            num_layers=num_layers_in_out_proj,\n",
        "            act=act,\n",
        "            input_residual=True,\n",
        "            output_residual=False,\n",
        "        )\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            FLAREBlock(\n",
        "                channel_dim=channel_dim,\n",
        "                num_heads=num_heads,\n",
        "                act=act,\n",
        "                rmsnorm=rmsnorm,\n",
        "                attn_scale=attn_scale,\n",
        "                num_latents=num_latents,\n",
        "                num_layers_kv_proj=num_layers_kv_proj,\n",
        "                num_layers_ffn=num_layers_ffn,\n",
        "                kv_proj_mlp_ratio=kv_proj_mlp_ratio,\n",
        "                ffn_mlp_ratio=ffn_mlp_ratio,\n",
        "            )\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0.)\n",
        "        elif isinstance(m, (nn.LayerNorm, nn.RMSNorm)):\n",
        "            if hasattr(m, 'weight') and m.weight is not None:\n",
        "                nn.init.constant_(m.weight, 1.)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0.)\n",
        "\n",
        "    def forward(self, x, return_scores: bool = False):\n",
        "        # x: [B, N, C]\n",
        "\n",
        "        if return_scores:\n",
        "            scores = []\n",
        "\n",
        "        x = self.in_proj(x)\n",
        "        for block in self.blocks:\n",
        "            x, score = block(x, return_scores=return_scores)\n",
        "            if return_scores:\n",
        "                scores.append(score)\n",
        "\n",
        "        x = self.out_proj['mlp'](self.out_proj['ln'](x))\n",
        "\n",
        "        return (x, scores) if return_scores else x\n",
        "\n",
        "#======================================================================#\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "b2365749",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_from_checkpoint(checkpoint_dir, metadata, device):\n",
        "    \"\"\"Load FLARE model from checkpoint directory.\"\"\"\n",
        "    # Load config\n",
        "    config_path = os.path.join(checkpoint_dir, 'config.yaml')\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    # Find latest checkpoint\n",
        "    ckpt_dirs = [d for d in os.listdir(checkpoint_dir) if d.startswith('ckpt')]\n",
        "    if not ckpt_dirs:\n",
        "        raise ValueError(f\"No checkpoint directories found in {checkpoint_dir}\")\n",
        "    latest_ckpt = sorted(ckpt_dirs, key=lambda x: int(x.replace('ckpt', '')))[-1]\n",
        "    model_path = os.path.join(checkpoint_dir, latest_ckpt, 'model.pt')\n",
        "    \n",
        "    print(f\"Loading model from: {model_path}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = FLAREModel(\n",
        "        in_dim=metadata['c_in'],\n",
        "        out_dim=metadata['c_out'],\n",
        "        channel_dim=config['channel_dim'],\n",
        "        num_blocks=config['num_blocks'],\n",
        "        num_latents=config['num_latents'],\n",
        "        num_heads=config['num_heads'],\n",
        "        act=config.get('act', None),\n",
        "        num_layers_kv_proj=config.get('num_layers_kv_proj', 3),\n",
        "        num_layers_ffn=config.get('num_layers_mlp', 3),\n",
        "        num_layers_in_out_proj=config.get('num_layers_in_out_proj', 2),\n",
        "        ffn_mlp_ratio=config.get('mlp_ratio', 1.0),\n",
        "        kv_proj_mlp_ratio=config.get('kv_proj_ratio', 1.0),\n",
        "        # in_out_proj_ratio=config.get('in_out_proj_ratio', 1.0),\n",
        "        out_proj_norm=config.get('out_proj_ln', True),\n",
        "    )\n",
        "    \n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Extract model state - check if checkpoint has 'model_state' key\n",
        "    if 'model_state' in checkpoint:\n",
        "        model_state = checkpoint['model_state']\n",
        "    else:\n",
        "        # If no 'model_state' key, assume the checkpoint itself is the state dict\n",
        "        model_state = checkpoint\n",
        "    \n",
        "    # Handle DDP wrapped models\n",
        "    if any(k.startswith('_orig_mod.') for k in model_state.keys()):\n",
        "        model_state = {k.replace('_orig_mod.', ''): v for k, v in model_state.items()}\n",
        "    \n",
        "    model.load_state_dict(model_state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Model loaded successfully! Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    return model, latest_ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "85f499c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_rel_l2_error(model, test_data, metadata, device, batch_size=1):\n",
        "    \"\"\"Calculate RelL2 error for entire test dataset.\"\"\"\n",
        "    model.eval()\n",
        "    rel_l2_loss = pdebench.RelL2Loss()\n",
        "    y_normalizer = metadata['y_normalizer'].to(device)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    total_error = 0.0\n",
        "    total_samples = 0\n",
        "    \n",
        "    print(f\"Calculating RelL2 error on {len(test_data)} test samples...\")\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            x, y = batch[0].to(device), batch[1].to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            yh = model(x)\n",
        "            \n",
        "            # Decode from normalized space\n",
        "            yh_decoded = y_normalizer.decode(yh)\n",
        "            y_decoded = y_normalizer.decode(y)\n",
        "            \n",
        "            # Calculate error\n",
        "            error = rel_l2_loss(yh_decoded, y_decoded)\n",
        "            \n",
        "            batch_size_actual = x.shape[0]\n",
        "            total_error += error.item() * batch_size_actual\n",
        "            total_samples += batch_size_actual\n",
        "            \n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"  Processed {i+1}/{len(test_loader)} batches...\")\n",
        "    \n",
        "    mean_error = total_error / total_samples\n",
        "    print(f\"\\nRelL2 Error on test set: {mean_error:.6e}\")\n",
        "    return mean_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "ce107af0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_elasticity(x, y_true, y_pred, sample_idx=0):\n",
        "    \"\"\"Visualize elasticity dataset (unstructured mesh).\"\"\"\n",
        "    # Enable LaTeX rendering\n",
        "    plt.rcParams['text.usetex'] = False\n",
        "    plt.rcParams['mathtext.fontset'] = 'stix'\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    \n",
        "    # Get sample data\n",
        "    x_sample = x[sample_idx].cpu().numpy()  # [N, 2]\n",
        "    y_true_sample = y_true[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    y_pred_sample = y_pred[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    error_sample = y_true_sample - y_pred_sample\n",
        "    \n",
        "    # Determine colorbar limits for first two plots (Ground Truth and Prediction)\n",
        "    vmin_gt_pred = min(y_true_sample.min(), y_pred_sample.min())\n",
        "    vmax_gt_pred = max(y_true_sample.max(), y_pred_sample.max())\n",
        "    \n",
        "    # Layout: 3 equal plot axes; add dedicated colorbar axes manually\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    fig.subplots_adjust(wspace=0.35)\n",
        "    ax0, ax1, ax2 = axes\n",
        "\n",
        "    # Tighten ONLY gap between plot 1 and 2 (keep 2↔3 spacing unchanged)\n",
        "    p0 = ax0.get_position()\n",
        "    p1 = ax1.get_position()\n",
        "    g12 = p1.x0 - p0.x1\n",
        "    scale12 = 0.6  # keep 60% of original gap\n",
        "    d = max(0.0, (g12 - g12 * scale12) / 2.0)\n",
        "    if d > 0:\n",
        "        ax0.set_position([p0.x0, p0.y0, p0.width + d, p0.height])\n",
        "        ax1.set_position([p1.x0 - d, p1.y0, p1.width + d, p1.height])\n",
        "\n",
        "    # Ground Truth\n",
        "    scatter1 = ax0.scatter(x_sample[:, 0], x_sample[:, 1], c=y_true_sample,\n",
        "                           cmap='RdBu_r', s=75, vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax0.set_title('Ground Truth', fontsize=24, fontfamily='serif')\n",
        "    ax0.axis('off')\n",
        "    ax0.set_aspect('equal')\n",
        "\n",
        "    # Prediction\n",
        "    scatter2 = ax1.scatter(x_sample[:, 0], x_sample[:, 1], c=y_pred_sample,\n",
        "                           cmap='RdBu_r', s=75, vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax1.set_title('Prediction', fontsize=24, fontfamily='serif')\n",
        "    ax1.axis('off')\n",
        "    ax1.set_aspect('equal')\n",
        "\n",
        "    # Error\n",
        "    scatter3 = ax2.scatter(x_sample[:, 0], x_sample[:, 1], c=error_sample,\n",
        "                           cmap='RdBu_r', s=75)\n",
        "    ax2.set_title('Error', fontsize=24, fontfamily='serif')\n",
        "    ax2.axis('off')\n",
        "    ax2.set_aspect('equal')\n",
        "\n",
        "    # Tick formatter: fixed-point, one decimal (e.g. 0.0)\n",
        "    from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "    def format_func(value, pos):\n",
        "        v = 0.0 if abs(value) < 1e-12 else value\n",
        "        s = f\"{v:.1f}\"\n",
        "        return \"0.0\" if s == \"-0.0\" else s\n",
        "\n",
        "    formatter = FuncFormatter(format_func)\n",
        "\n",
        "    # Helper: colorbar axis same height as plot axis, tight to the right\n",
        "    def add_cbar_next_to(ax_left, mappable, *, x_max=None):\n",
        "        pad = 0.004\n",
        "        width = 0.014\n",
        "        pos = ax_left.get_position()\n",
        "        x = pos.x1 + pad\n",
        "        if x_max is not None:\n",
        "            x = min(x, x_max)\n",
        "        x = min(x, 0.985 - width)\n",
        "        cax = fig.add_axes([x, pos.y0, width, pos.height])\n",
        "        cbar = fig.colorbar(mappable, cax=cax)\n",
        "        cbar.ax.yaxis.set_major_formatter(formatter)\n",
        "        cbar.ax.yaxis.get_offset_text().set_visible(False)\n",
        "        cbar.ax.tick_params(labelsize=10)\n",
        "        cbar.update_ticks()\n",
        "        return cbar\n",
        "\n",
        "    # Shared cbar tight to the right of plot 2, but don't overlap plot 3\n",
        "    pos2 = ax2.get_position()\n",
        "    x_max_shared = pos2.x0 - 0.004 - 0.014\n",
        "    _ = add_cbar_next_to(ax1, scatter1, x_max=x_max_shared)\n",
        "\n",
        "    # Error cbar tight to the right of plot 3\n",
        "    _ = add_cbar_next_to(ax2, scatter3)\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "866a365f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_structured_2d(x, y_true, y_pred, metadata, sample_idx=0):\n",
        "    \"\"\"Visualize structured 2D datasets (darcy).\"\"\"\n",
        "    # Enable LaTeX rendering\n",
        "    plt.rcParams['text.usetex'] = False\n",
        "    plt.rcParams['mathtext.fontset'] = 'stix'\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    \n",
        "    H = metadata['H']\n",
        "    W = metadata['W']\n",
        "    \n",
        "    # Get sample data - x is [batch, N, c_in]\n",
        "    x_sample = x[sample_idx].cpu().numpy()  # [N, c_in]\n",
        "    y_true_sample = y_true[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    y_pred_sample = y_pred[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    error_sample = y_true_sample - y_pred_sample\n",
        "    \n",
        "    # Reshape to 2D grid\n",
        "    y_true_2d = y_true_sample.reshape(H, W)\n",
        "    y_pred_2d = y_pred_sample.reshape(H, W)\n",
        "    error_2d = error_sample.reshape(H, W)\n",
        "    \n",
        "    # Extract coordinates\n",
        "    # For darcy: input is [pos_x, pos_y, coeff], so first 2 dims are positions\n",
        "    if x_sample.shape[1] >= 2:\n",
        "        x_coords = x_sample[:, 0].reshape(H, W)\n",
        "        y_coords = x_sample[:, 1].reshape(H, W)\n",
        "        x_min, x_max = x_coords.min(), x_coords.max()\n",
        "        y_min, y_max = y_coords.min(), y_coords.max()\n",
        "    else:\n",
        "        # Fallback: use grid indices\n",
        "        x_coords = np.linspace(0, 1, W)\n",
        "        y_coords = np.linspace(0, 1, H)\n",
        "        x_coords, y_coords = np.meshgrid(x_coords, y_coords)\n",
        "        x_min, x_max = 0, 1\n",
        "        y_min, y_max = 0, 1\n",
        "    \n",
        "    # Layout: 3 equal plot axes; add dedicated colorbar axes manually\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    fig.subplots_adjust(wspace=0.35)\n",
        "    ax0, ax1, ax2 = axes\n",
        "\n",
        "    # Tighten ONLY gap between plot 1 and 2 (keep 2↔3 spacing unchanged)\n",
        "    p0 = ax0.get_position()\n",
        "    p1 = ax1.get_position()\n",
        "    g12 = p1.x0 - p0.x1\n",
        "    scale12 = 0.6  # keep 60% of original gap\n",
        "    d = max(0.0, (g12 - g12 * scale12) / 2.0)\n",
        "    if d > 0:\n",
        "        ax0.set_position([p0.x0, p0.y0, p0.width + d, p0.height])\n",
        "        ax1.set_position([p1.x0 - d, p1.y0, p1.width + d, p1.height])\n",
        "\n",
        "    # Determine colorbar limits for first two plots (Ground Truth and Prediction)\n",
        "    vmin_gt_pred = min(y_true_2d.min(), y_pred_2d.min())\n",
        "    vmax_gt_pred = max(y_true_2d.max(), y_pred_2d.max())\n",
        "\n",
        "    # Ground Truth\n",
        "    im1 = ax0.imshow(y_true_2d, cmap='RdBu_r', origin='lower',\n",
        "                     extent=[x_min, x_max, y_min, y_max],\n",
        "                     aspect='auto', vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax0.set_title('Ground Truth', fontsize=24, fontfamily='serif')\n",
        "    ax0.axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    im2 = ax1.imshow(y_pred_2d, cmap='RdBu_r', origin='lower',\n",
        "                     extent=[x_min, x_max, y_min, y_max],\n",
        "                     aspect='auto', vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax1.set_title('Prediction', fontsize=24, fontfamily='serif')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Error\n",
        "    im3 = ax2.imshow(error_2d, cmap='RdBu_r', origin='lower',\n",
        "                     extent=[x_min, x_max, y_min, y_max],\n",
        "                     aspect='auto')\n",
        "    ax2.set_title('Error', fontsize=24, fontfamily='serif')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Tick formatter: fixed-point, one decimal (e.g. 0.0)\n",
        "    from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "    def format_func(value, pos):\n",
        "        v = 0.0 if abs(value) < 1e-12 else value\n",
        "        s = f\"{v:.1f}\"\n",
        "        return \"0.0\" if s == \"-0.0\" else s\n",
        "\n",
        "    formatter = FuncFormatter(format_func)\n",
        "\n",
        "    def add_cbar_next_to(ax_left, mappable, *, x_max=None):\n",
        "        pad = 0.004\n",
        "        width = 0.014\n",
        "        pos = ax_left.get_position()\n",
        "        x = pos.x1 + pad\n",
        "        if x_max is not None:\n",
        "            x = min(x, x_max)\n",
        "        x = min(x, 0.985 - width)\n",
        "        cax = fig.add_axes([x, pos.y0, width, pos.height])\n",
        "        cbar = fig.colorbar(mappable, cax=cax)\n",
        "        cbar.ax.yaxis.set_major_formatter(formatter)\n",
        "        cbar.ax.yaxis.get_offset_text().set_visible(False)\n",
        "        cbar.ax.tick_params(labelsize=10)\n",
        "        cbar.update_ticks()\n",
        "        return cbar\n",
        "\n",
        "    # Shared cbar tight to the right of plot 2, but don't overlap plot 3\n",
        "    pos2 = ax2.get_position()\n",
        "    x_max_shared = pos2.x0 - 0.004 - 0.014\n",
        "    _ = add_cbar_next_to(ax1, im1, x_max=x_max_shared)\n",
        "\n",
        "    # Error cbar tight to the right of plot 3\n",
        "    _ = add_cbar_next_to(ax2, im3)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def visualize_original_coords(x, y_true, y_pred, metadata, sample_idx=0, device='cpu'):\n",
        "    \"\"\"Visualize datasets with original X, Y coordinates (pipe).\n",
        "    \n",
        "    For pipe: The coordinates need to be decoded from normalized space.\n",
        "    \"\"\"\n",
        "    # Enable LaTeX rendering\n",
        "    plt.rcParams['text.usetex'] = False\n",
        "    plt.rcParams['mathtext.fontset'] = 'stix'\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    \n",
        "    # Get sample data - x is [batch, N, c_in] where batch=1\n",
        "    # Remove batch dimension to get [N, c_in]\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        if x.dim() == 3:\n",
        "            x_sample = x[sample_idx].cpu().numpy()  # [N, c_in]\n",
        "        else:\n",
        "            x_sample = x.cpu().numpy()  # [N, c_in] (already no batch dim)\n",
        "    else:\n",
        "        # Already numpy array\n",
        "        if x.ndim == 3:\n",
        "            x_sample = x[sample_idx]  # [N, c_in]\n",
        "        else:\n",
        "            x_sample = x  # [N, c_in]\n",
        "    \n",
        "    y_true_sample = y_true[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    y_pred_sample = y_pred[sample_idx].cpu().numpy().squeeze()  # [N]\n",
        "    error_sample = y_true_sample - y_pred_sample\n",
        "    \n",
        "    # Ensure x_sample has correct shape [N, c_in] - remove any extra batch dimensions\n",
        "    while x_sample.ndim > 2:\n",
        "        x_sample = x_sample.squeeze(0)\n",
        "    \n",
        "    if x_sample.ndim != 2:\n",
        "        raise ValueError(f\"x_sample should be 2D [N, c_in], got shape: {x_sample.shape}\")\n",
        "    \n",
        "    # Extract original coordinates\n",
        "    # For pipe: x_normalizer is UnitGaussianNormalizer, so we need to decode\n",
        "    if 'x_normalizer' in metadata and metadata['x_normalizer'] is not None:\n",
        "        x_normalizer = metadata['x_normalizer']\n",
        "        \n",
        "        # Check if it's an IdentityNormalizer (no decoding needed)\n",
        "        if type(x_normalizer).__name__ == 'IdentityNormalizer' or not hasattr(x_normalizer, 'decode'):\n",
        "            # Identity normalizer - coordinates are already in original space\n",
        "            x_sample_decoded = x_sample\n",
        "        else:\n",
        "            # UnitGaussianNormalizer or similar - need to decode\n",
        "            # Move normalizer to device if it has parameters\n",
        "            if hasattr(x_normalizer, 'mean') or hasattr(x_normalizer, 'to'):\n",
        "                try:\n",
        "                    x_normalizer = x_normalizer.to(device)\n",
        "                except:\n",
        "                    pass\n",
        "            \n",
        "            # Decode coordinates if they were normalized\n",
        "            # x_sample is [N, c_in], convert to tensor\n",
        "            x_sample_tensor = torch.tensor(x_sample, dtype=torch.float32).to(device)\n",
        "            x_sample_decoded = x_normalizer.decode(x_sample_tensor).cpu().numpy()\n",
        "            \n",
        "            # Remove any extra dimensions\n",
        "            while x_sample_decoded.ndim > 2:\n",
        "                x_sample_decoded = x_sample_decoded.squeeze(0)\n",
        "            \n",
        "            # Ensure shape is [N, c_in]\n",
        "            if x_sample_decoded.ndim == 1:\n",
        "                x_sample_decoded = x_sample_decoded.reshape(-1, x_sample.shape[1])\n",
        "    else:\n",
        "        x_sample_decoded = x_sample\n",
        "    \n",
        "    # Ensure x_sample_decoded has shape [N, c_in] - remove any batch dimensions\n",
        "    while x_sample_decoded.ndim > 2:\n",
        "        x_sample_decoded = x_sample_decoded.squeeze(0)\n",
        "    \n",
        "    if x_sample_decoded.ndim != 2:\n",
        "        raise ValueError(f\"x_sample_decoded should be 2D [N, c_in], got shape: {x_sample_decoded.shape}\")\n",
        "    \n",
        "    # Check if shape is [N, c_in] or [c_in, N] and fix if needed\n",
        "    if x_sample_decoded.shape[0] < x_sample_decoded.shape[1] and x_sample_decoded.shape[0] == metadata.get('c_in', 2):\n",
        "        # Likely transposed: [c_in, N] -> transpose to [N, c_in]\n",
        "        x_sample_decoded = x_sample_decoded.T\n",
        "    \n",
        "    # Extract X, Y coordinates (first 2 dimensions)\n",
        "    # x_sample_decoded is [N, c_in], so [:, 0] gives [N] for X, [:, 1] gives [N] for Y\n",
        "    x_coords = x_sample_decoded[:, 0].flatten()\n",
        "    y_coords = x_sample_decoded[:, 1].flatten()\n",
        "    \n",
        "    # Ensure shapes match\n",
        "    if len(x_coords) != len(y_true_sample):\n",
        "        raise ValueError(f\"Coordinate shape mismatch: x_coords={x_coords.shape} (len={len(x_coords)}), y_coords={y_coords.shape} (len={len(y_coords)}), y_true={y_true_sample.shape} (len={len(y_true_sample)}), x_sample_decoded shape={x_sample_decoded.shape}\")\n",
        "    \n",
        "    # Determine colorbar limits for first two plots (Ground Truth and Prediction)\n",
        "    vmin_gt_pred = min(y_true_sample.min(), y_pred_sample.min())\n",
        "    vmax_gt_pred = max(y_true_sample.max(), y_pred_sample.max())\n",
        "    \n",
        "    # Layout: 3 equal plot axes; add dedicated colorbar axes manually\n",
        "    # Make the figure taller so each plot area can be square (adds vertical whitespace)\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
        "    fig.subplots_adjust(wspace=0.35)\n",
        "    ax0, ax1, ax2 = axes\n",
        "\n",
        "    # Tighten ONLY gap between plot 1 and 2 (keep 2↔3 spacing unchanged)\n",
        "    p0 = ax0.get_position()\n",
        "    p1 = ax1.get_position()\n",
        "    g12 = p1.x0 - p0.x1\n",
        "    scale12 = 0.6  # keep 60% of original gap\n",
        "    d = max(0.0, (g12 - g12 * scale12) / 2.0)\n",
        "    if d > 0:\n",
        "        ax0.set_position([p0.x0, p0.y0, p0.width + d, p0.height])\n",
        "        ax1.set_position([p1.x0 - d, p1.y0, p1.width + d, p1.height])\n",
        "\n",
        "    # Ensure each axes box is square\n",
        "    for ax in (ax0, ax1, ax2):\n",
        "        ax.set_aspect('equal', adjustable='box')\n",
        "        try:\n",
        "            ax.set_box_aspect(1)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Ground Truth\n",
        "    scatter1 = ax0.scatter(x_coords, y_coords, c=y_true_sample,\n",
        "                           cmap='RdBu_r', s=1, vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax0.set_title('Ground Truth', fontsize=24, fontfamily='serif')\n",
        "    ax0.axis('off')\n",
        "    ax0.set_aspect('equal')\n",
        "\n",
        "    # Prediction\n",
        "    scatter2 = ax1.scatter(x_coords, y_coords, c=y_pred_sample,\n",
        "                           cmap='RdBu_r', s=1, vmin=vmin_gt_pred, vmax=vmax_gt_pred)\n",
        "    ax1.set_title('Prediction', fontsize=24, fontfamily='serif')\n",
        "    ax1.axis('off')\n",
        "    ax1.set_aspect('equal')\n",
        "\n",
        "    # Error\n",
        "    scatter3 = ax2.scatter(x_coords, y_coords, c=error_sample,\n",
        "                           cmap='RdBu_r', s=1)\n",
        "    ax2.set_title('Error', fontsize=24, fontfamily='serif')\n",
        "    ax2.axis('off')\n",
        "    ax2.set_aspect('equal')\n",
        "\n",
        "    # Tick formatter: fixed-point, one decimal (e.g. 0.0)\n",
        "    from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "    def format_func(value, pos):\n",
        "        v = 0.0 if abs(value) < 1e-12 else value\n",
        "        s = f\"{v:.1f}\"\n",
        "        return \"0.0\" if s == \"-0.0\" else s\n",
        "\n",
        "    formatter = FuncFormatter(format_func)\n",
        "\n",
        "    def add_cbar_next_to(ax_left, mappable, *, x_max=None):\n",
        "        pad = 0.004\n",
        "        width = 0.014\n",
        "        pos = ax_left.get_position()\n",
        "        x = pos.x1 + pad\n",
        "        if x_max is not None:\n",
        "            x = min(x, x_max)\n",
        "        x = min(x, 0.985 - width)\n",
        "        cax = fig.add_axes([x, pos.y0, width, pos.height])\n",
        "        cbar = fig.colorbar(mappable, cax=cax)\n",
        "        cbar.ax.yaxis.set_major_formatter(formatter)\n",
        "        cbar.ax.yaxis.get_offset_text().set_visible(False)\n",
        "        cbar.ax.tick_params(labelsize=10)\n",
        "        cbar.update_ticks()\n",
        "        return cbar\n",
        "\n",
        "    # Shared cbar tight to the right of plot 2, but don't overlap plot 3\n",
        "    pos2 = ax2.get_position()\n",
        "    x_max_shared = pos2.x0 - 0.004 - 0.014\n",
        "    _ = add_cbar_next_to(ax1, scatter1, x_max=x_max_shared)\n",
        "\n",
        "    # Error cbar tight to the right of plot 3\n",
        "    _ = add_cbar_next_to(ax2, scatter3)\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "4ed2458e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Processing dataset: elasticity\n",
            "================================================================================\n",
            "\n",
            "Loading dataset: elasticity\n",
            "Train samples: 1000, Test samples: 200\n",
            "Input dim: 2, Output dim: 1\n",
            "Checkpoint directory: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_elasticity_B_8_C_64_M_64_H_8\n",
            "Loading model from: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_elasticity_B_8_C_64_M_64_H_8/ckpt10/model.pt\n",
            "Model loaded successfully! Parameters: 592,641\n",
            "Calculating RelL2 error on 200 test samples...\n",
            "  Processed 10/200 batches...\n",
            "  Processed 20/200 batches...\n",
            "  Processed 30/200 batches...\n",
            "  Processed 40/200 batches...\n",
            "  Processed 50/200 batches...\n",
            "  Processed 60/200 batches...\n",
            "  Processed 70/200 batches...\n",
            "  Processed 80/200 batches...\n",
            "  Processed 90/200 batches...\n",
            "  Processed 100/200 batches...\n",
            "  Processed 110/200 batches...\n",
            "  Processed 120/200 batches...\n",
            "  Processed 130/200 batches...\n",
            "  Processed 140/200 batches...\n",
            "  Processed 150/200 batches...\n",
            "  Processed 160/200 batches...\n",
            "  Processed 170/200 batches...\n",
            "  Processed 180/200 batches...\n",
            "  Processed 190/200 batches...\n",
            "  Processed 200/200 batches...\n",
            "\n",
            "RelL2 Error on test set: 3.805151e-03\n",
            "\n",
            "Visualizing sample 0...\n",
            "Saved visualization to: /home/vedantpu/.julia/dev/FLARE-dev.py/figs/vis_out/elasticity_visualization.png\n",
            "\n",
            "Visualizing sample 1...\n",
            "Saved visualization to: /home/vedantpu/.julia/dev/FLARE-dev.py/figs/vis_out/elasticity1_visualization.png\n",
            "\n",
            "================================================================================\n",
            "Processing dataset: darcy\n",
            "================================================================================\n",
            "\n",
            "Loading dataset: darcy\n",
            "Train samples: 1000, Test samples: 200\n",
            "Input dim: 3, Output dim: 1\n",
            "Checkpoint directory: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_darcy_B_8_C_64_M_256_H_16\n",
            "Loading model from: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_darcy_B_8_C_64_M_256_H_16/ckpt10/model.pt\n",
            "Model loaded successfully! Parameters: 691,009\n",
            "Calculating RelL2 error on 200 test samples...\n",
            "  Processed 10/200 batches...\n",
            "  Processed 20/200 batches...\n",
            "  Processed 30/200 batches...\n",
            "  Processed 40/200 batches...\n",
            "  Processed 50/200 batches...\n",
            "  Processed 60/200 batches...\n",
            "  Processed 70/200 batches...\n",
            "  Processed 80/200 batches...\n",
            "  Processed 90/200 batches...\n",
            "  Processed 100/200 batches...\n",
            "  Processed 110/200 batches...\n",
            "  Processed 120/200 batches...\n",
            "  Processed 130/200 batches...\n",
            "  Processed 140/200 batches...\n",
            "  Processed 150/200 batches...\n",
            "  Processed 160/200 batches...\n",
            "  Processed 170/200 batches...\n",
            "  Processed 180/200 batches...\n",
            "  Processed 190/200 batches...\n",
            "  Processed 200/200 batches...\n",
            "\n",
            "RelL2 Error on test set: 1.778407e-02\n",
            "\n",
            "Visualizing sample 0...\n",
            "Saved visualization to: /home/vedantpu/.julia/dev/FLARE-dev.py/figs/vis_out/darcy_visualization.png\n",
            "\n",
            "================================================================================\n",
            "Processing dataset: pipe\n",
            "================================================================================\n",
            "\n",
            "Loading dataset: pipe\n",
            "Train samples: 1000, Test samples: 200\n",
            "Input dim: 2, Output dim: 1\n",
            "Checkpoint directory: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_pipe_B_8_C_64_M_128_H_8\n",
            "Loading model from: /home/vedantpu/.julia/dev/FLARE-dev.py/out/pdebench/vis_ckpts/model_2_pipe_B_8_C_64_M_128_H_8/ckpt10/model.pt\n",
            "Model loaded successfully! Parameters: 625,409\n",
            "Calculating RelL2 error on 200 test samples...\n",
            "  Processed 10/200 batches...\n",
            "  Processed 20/200 batches...\n",
            "  Processed 30/200 batches...\n",
            "  Processed 40/200 batches...\n",
            "  Processed 50/200 batches...\n",
            "  Processed 60/200 batches...\n",
            "  Processed 70/200 batches...\n",
            "  Processed 80/200 batches...\n",
            "  Processed 90/200 batches...\n",
            "  Processed 100/200 batches...\n",
            "  Processed 110/200 batches...\n",
            "  Processed 120/200 batches...\n",
            "  Processed 130/200 batches...\n",
            "  Processed 140/200 batches...\n",
            "  Processed 150/200 batches...\n",
            "  Processed 160/200 batches...\n",
            "  Processed 170/200 batches...\n",
            "  Processed 180/200 batches...\n",
            "  Processed 190/200 batches...\n",
            "  Processed 200/200 batches...\n",
            "\n",
            "RelL2 Error on test set: 3.426765e-03\n",
            "\n",
            "Visualizing sample 0...\n",
            "Saved visualization to: /home/vedantpu/.julia/dev/FLARE-dev.py/figs/vis_out/pipe_visualization.png\n",
            "\n",
            "================================================================================\n",
            "Summary of RelL2 Errors:\n",
            "================================================================================\n",
            "elasticity          : 3.805151e-03\n",
            "darcy               : 1.778407e-02\n",
            "pipe                : 3.426765e-03\n"
          ]
        }
      ],
      "source": [
        "# Main visualization loop\n",
        "results = {}\n",
        "\n",
        "for dataset_name in datasets_to_visualize:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Processing dataset: {dataset_name}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Load dataset\n",
        "    print(f\"\\nLoading dataset: {dataset_name}\")\n",
        "    train_data, test_data, metadata = load_dataset(\n",
        "        dataset_name, DATADIR_BASE, PROJDIR, mesh=False\n",
        "    )\n",
        "    print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
        "    print(f\"Input dim: {metadata['c_in']}, Output dim: {metadata['c_out']}\")\n",
        "    \n",
        "    # Find checkpoint directory\n",
        "    checkpoint_dir = None\n",
        "    for item in os.listdir(CHECKPOINT_BASE):\n",
        "        if item.startswith(f'model_2_{dataset_name}'):\n",
        "            checkpoint_dir = os.path.join(CHECKPOINT_BASE, item)\n",
        "            break\n",
        "    \n",
        "    if checkpoint_dir is None:\n",
        "        print(f\"Warning: No checkpoint found for {dataset_name}, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"Checkpoint directory: {checkpoint_dir}\")\n",
        "    \n",
        "    # Load model\n",
        "    model, ckpt_name = load_model_from_checkpoint(checkpoint_dir, metadata, device)\n",
        "    \n",
        "    # Calculate RelL2 error on test set\n",
        "    rel_l2_error = calculate_rel_l2_error(model, test_data, metadata, device, batch_size=1)\n",
        "    results[dataset_name] = {'rel_l2_error': rel_l2_error}\n",
        "    \n",
        "    # For elasticity, save two samples (0 and 1). Others: just sample 0.\n",
        "    sample_indices = [0, 1] if dataset_name == 'elasticity' else [0]\n",
        "\n",
        "    for sample_idx in sample_indices:\n",
        "        # Get a sample for visualization\n",
        "        x_sample_orig, y_true_sample = test_data[sample_idx]  # Original coordinates from dataset\n",
        "        x_sample = x_sample_orig.unsqueeze(0).to(device)  # Add batch dimension for model\n",
        "\n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            y_pred_normalized = model(x_sample)\n",
        "\n",
        "        # Decode from normalized space\n",
        "        y_normalizer = metadata['y_normalizer'].to(device)\n",
        "        y_true_decoded = y_normalizer.decode(y_true_sample.unsqueeze(0).to(device))\n",
        "        y_pred_decoded = y_normalizer.decode(y_pred_normalized)\n",
        "\n",
        "        # Visualize\n",
        "        print(f\"\\nVisualizing sample {sample_idx}...\")\n",
        "        if dataset_name == 'elasticity':\n",
        "            fig = visualize_elasticity(x_sample, y_true_decoded, y_pred_decoded, sample_idx=0)\n",
        "        elif dataset_name == 'darcy':\n",
        "            fig = visualize_structured_2d(x_sample, y_true_decoded, y_pred_decoded, metadata, sample_idx=0)\n",
        "        elif dataset_name == 'airfoil_steady':\n",
        "            print(f\"Skipping visualization for {dataset_name} (not implemented yet)\")\n",
        "            continue\n",
        "        else:  # pipe - use original coordinates\n",
        "            fig = visualize_original_coords(\n",
        "                x_sample_orig.unsqueeze(0),\n",
        "                y_true_decoded,\n",
        "                y_pred_decoded,\n",
        "                metadata,\n",
        "                sample_idx=0,\n",
        "                device=device,\n",
        "            )\n",
        "\n",
        "        # Save figure\n",
        "        os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
        "        if dataset_name == 'elasticity' and sample_idx == 1:\n",
        "            out_name = 'elasticity1_visualization.png'\n",
        "        else:\n",
        "            out_name = f'{dataset_name}_visualization.png'\n",
        "        fig_path = os.path.join(OUTPUT_BASE, out_name)\n",
        "        fig.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Saved visualization to: {fig_path}\")\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Summary of RelL2 Errors:\")\n",
        "print(\"=\"*80)\n",
        "for dataset_name, result in results.items():\n",
        "    print(f\"{dataset_name:20s}: {result['rel_l2_error']:.6e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97578ca7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefe9574",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
